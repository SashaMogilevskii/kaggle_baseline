{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import re\nimport gc\nfrom tqdm.notebook import tqdm\nimport random\nimport time \nimport pandas as pd\nimport numpy as np \nimport psutil\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import TensorDataset, Dataset, random_split, DataLoader, RandomSampler, SequentialSampler\nfrom transformers import get_cosine_schedule_with_warmup, AdamW, AutoTokenizer\n\n\n\nfrom transformers import  AutoModelForSequenceClassification\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss\n\n\n\n# seed_val = 177\n# random.seed(seed_val)\n# np.random.seed(seed_val)\n# torch.manual_seed(seed_val)\n# torch.cuda.manual_seed_all(seed_val)","metadata":{"execution":{"iopub.status.busy":"2022-08-16T14:31:20.470984Z","iopub.execute_input":"2022-08-16T14:31:20.472198Z","iopub.status.idle":"2022-08-16T14:31:28.843347Z","shell.execute_reply.started":"2022-08-16T14:31:20.472091Z","shell.execute_reply":"2022-08-16T14:31:28.842350Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device('cuda')\n    print('Thera are  %d GPU(s) available.' % torch.cuda.device_count())\n    print(torch.cuda.get_device_name(device=None))\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-08-16T14:31:28.845808Z","iopub.execute_input":"2022-08-16T14:31:28.846536Z","iopub.status.idle":"2022-08-16T14:31:28.929340Z","shell.execute_reply.started":"2022-08-16T14:31:28.846492Z","shell.execute_reply":"2022-08-16T14:31:28.928233Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\n# model_name = \"microsoft/deberta-v2-xlarge\"\n# model_name = \"microsoft/deberta-v3-base\"\nmodel_name = \"microsoft/deberta-v3-base\"\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, \n                                                           num_labels=3,\n                                                          output_attentions = False,\n                                                            output_hidden_states = False,).to(device)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmax_length = 128\ntokenizer.model_max_length = max_length","metadata":{"execution":{"iopub.status.busy":"2022-08-16T14:31:28.930890Z","iopub.execute_input":"2022-08-16T14:31:28.931526Z","iopub.status.idle":"2022-08-16T14:31:48.446424Z","shell.execute_reply.started":"2022-08-16T14:31:28.931483Z","shell.execute_reply":"2022-08-16T14:31:48.445257Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/feedback-prize-effectiveness/train.csv')\n# df = df.sample(df.shape[0] // 10)","metadata":{"execution":{"iopub.status.busy":"2022-08-16T14:31:48.450019Z","iopub.execute_input":"2022-08-16T14:31:48.450535Z","iopub.status.idle":"2022-08-16T14:31:48.811936Z","shell.execute_reply.started":"2022-08-16T14:31:48.450490Z","shell.execute_reply":"2022-08-16T14:31:48.810636Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def normalise(text):\n#     text = text.lower()\n#     text = text.strip()\n    text = re.sub(\"\\n\", \" \", text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-08-16T14:31:48.813933Z","iopub.execute_input":"2022-08-16T14:31:48.814372Z","iopub.status.idle":"2022-08-16T14:31:48.820606Z","shell.execute_reply.started":"2022-08-16T14:31:48.814329Z","shell.execute_reply":"2022-08-16T14:31:48.819422Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df[\"essay_text\"] = df[\"essay_id\"].apply(lambda x: open(f'../input/feedback-prize-effectiveness/train/{x}.txt').read())\ndf['discourse_type'] = df['discourse_type'].apply(normalise)\ndf['discourse_text'] = df['discourse_text'].apply(normalise)\ndf['essay_text'] = df['essay_text'].apply(normalise)\ndf['text_features'] =  df['discourse_type'] + tokenizer.sep_token + df['discourse_text'] + tokenizer.sep_token + df['essay_text']\ndf.drop(['discourse_id', 'essay_id', 'essay_text', 'discourse_text', 'discourse_type'], axis=1, inplace=True )","metadata":{"execution":{"iopub.status.busy":"2022-08-16T14:31:48.822249Z","iopub.execute_input":"2022-08-16T14:31:48.822907Z","iopub.status.idle":"2022-08-16T14:32:22.794889Z","shell.execute_reply.started":"2022-08-16T14:31:48.822868Z","shell.execute_reply":"2022-08-16T14:32:22.793909Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"classes_to_labels = {\n    \"Adequate\":1,\n    \"Effective\":2,\n    \"Ineffective\":0,\n}\ndf['discourse_effectiveness'] = df['discourse_effectiveness'].map(classes_to_labels)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-16T14:32:22.796604Z","iopub.execute_input":"2022-08-16T14:32:22.796955Z","iopub.status.idle":"2022-08-16T14:32:22.807800Z","shell.execute_reply.started":"2022-08-16T14:32:22.796919Z","shell.execute_reply":"2022-08-16T14:32:22.806761Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-16T14:32:22.809432Z","iopub.execute_input":"2022-08-16T14:32:22.809799Z","iopub.status.idle":"2022-08-16T14:32:22.837787Z","shell.execute_reply.started":"2022-08-16T14:32:22.809764Z","shell.execute_reply":"2022-08-16T14:32:22.836923Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"sentences = df.text_features.values\nlabels = df.discourse_effectiveness.values","metadata":{"execution":{"iopub.status.busy":"2022-08-16T14:32:22.839059Z","iopub.execute_input":"2022-08-16T14:32:22.839423Z","iopub.status.idle":"2022-08-16T14:32:22.846903Z","shell.execute_reply.started":"2022-08-16T14:32:22.839388Z","shell.execute_reply":"2022-08-16T14:32:22.845941Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"input_ids = []\nattention_masks = []\nfor sent in tqdm(sentences):\n    encoded_dict = tokenizer.encode_plus(\n        sent, \n        add_special_tokens = True,\n        max_length = max_length,\n        pad_to_max_length = True,\n        return_attention_mask = True,\n        return_tensors = 'pt'\n    )\n    \n    input_ids.append(encoded_dict['input_ids'])\n    attention_masks.append(encoded_dict['attention_mask'])\n\ninput_ids = torch.cat(input_ids, dim=0)\nattention_masks = torch.cat(attention_masks, dim=0)\ny = torch.tensor(labels)","metadata":{"execution":{"iopub.status.busy":"2022-08-16T14:32:22.852556Z","iopub.execute_input":"2022-08-16T14:32:22.852816Z","iopub.status.idle":"2022-08-16T14:34:10.807588Z","shell.execute_reply.started":"2022-08-16T14:32:22.852791Z","shell.execute_reply":"2022-08-16T14:34:10.806418Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"k_fold = 4\nrandom_state = 177\nStratified_KF = StratifiedKFold(n_splits=k_fold, shuffle=True)\nbatch_size = 10\n","metadata":{"execution":{"iopub.status.busy":"2022-08-16T14:34:10.811294Z","iopub.execute_input":"2022-08-16T14:34:10.812647Z","iopub.status.idle":"2022-08-16T14:34:10.818999Z","shell.execute_reply.started":"2022-08-16T14:34:10.812599Z","shell.execute_reply":"2022-08-16T14:34:10.817911Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"epochs = 1\nsoft_max = nn.Softmax(dim=1)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-16T14:34:10.820457Z","iopub.execute_input":"2022-08-16T14:34:10.821636Z","iopub.status.idle":"2022-08-16T14:34:10.830952Z","shell.execute_reply.started":"2022-08-16T14:34:10.821594Z","shell.execute_reply":"2022-08-16T14:34:10.829545Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# def Token_example( list_of_texts = None, index = 0):\n#     if list_of_texts is None:\n#         list_of_texts=['It is he' + str(tokenizer.sep_token) +'He is labrador.    His name is Zeus ' ]\n#     print('Original:', list_of_texts[index])\n#     print()\n#     print('With Token:', tokenizer.tokenize(list_of_texts[index]))\n#     print()\n#     print('With Token IDs:', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(list_of_texts[index])))\n#     print()\n# Token_example()","metadata":{"execution":{"iopub.status.busy":"2022-08-16T14:34:10.832992Z","iopub.execute_input":"2022-08-16T14:34:10.833667Z","iopub.status.idle":"2022-08-16T14:34:10.841021Z","shell.execute_reply.started":"2022-08-16T14:34:10.833625Z","shell.execute_reply":"2022-08-16T14:34:10.839748Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"\nprint(psutil.virtual_memory()) # Check free-memory\nfor epoch_i in (range(1, epochs + 1)):\n    \n\n    print(f'----------------------------epoch:{epoch_i}/{epochs}-------------------------')\n    \n    \n    \n    for fold, (train_id, val_id), in tqdm(enumerate(Stratified_KF.split(X=input_ids, y=labels))):\n        model = AutoModelForSequenceClassification.from_pretrained(model_name, \n                                                           num_labels=3,\n                                                          output_attentions = False,\n                                                            output_hidden_states = False,).to(device)\n        len_traindata = len(df) // k_fold * (k_fold - 1) // batch_size\n        optimizer = AdamW( model.parameters(),\n                          lr = 2e-5,\n                          eps = 1e-8)\n\n        total_steps = len_traindata * epochs * k_fold \n        scheduler = get_cosine_schedule_with_warmup( optimizer,\n                                                    num_warmup_steps=0,\n                                                    num_training_steps= total_steps)\n        total_train_loss = 0\n        total_eval_loss = 0\n        val_logloss = 0\n        start_time = time.time()\n        \n        input_ids_train_fold, input_ids_valid_fold = input_ids[train_id], input_ids[val_id]\n        attention_masks_train_fold, attention_masks_valid_fold =  attention_masks[train_id],attention_masks[val_id]\n        y_train_fold, y_valid_fold = torch.Tensor(labels[train_id]), torch.Tensor(labels[val_id])\n\n        train_dataset = TensorDataset(input_ids_train_fold, attention_masks_train_fold, y_train_fold)\n        valid_dataset = TensorDataset(input_ids_valid_fold, attention_masks_valid_fold, y_valid_fold)\n\n        train_dataloader = DataLoader(\n        train_dataset,\n        sampler = RandomSampler(train_dataset),\n        batch_size = batch_size\n        )\n\n        valid_dataloader = DataLoader(\n        valid_dataset,\n        sampler = SequentialSampler(valid_dataset),\n        batch_size = batch_size\n        )\n        \n        model.train()\n        \n        for batch in tqdm(train_dataloader):\n        \n            b_input_ids = batch[0].to(device)\n            b_input_mask = batch[1].to(device)\n            b_labels = batch[2].to(device)\n            \n            optimizer.zero_grad()\n            \n            res = model.forward(b_input_ids,\n                               token_type_ids=None,\n                               attention_mask=b_input_mask,\n                               labels = b_labels)\n            \n            loss_value = res['loss']\n            total_train_loss += loss_value\n            loss_value.backward()\n            \n#             torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n            scheduler.step()\n\n            del batch, res, loss_value\n            gc.collect()\n            \n            \n        list_of_logits = None\n        list_of_labels = None\n        model.eval()\n        for batch in valid_dataloader:\n            b_input_ids = batch[0].to(device)\n            b_input_mask = batch[1].to(device)\n            b_labels = batch[2].to(device)\n            with torch.no_grad():\n                res = model.forward(b_input_ids,\n                                   token_type_ids=None,\n                                   attention_mask=b_input_mask,\n                                   labels = b_labels)\n            \n                loss_value = res['loss']\n                total_eval_loss += loss_value\n        \n                \n                logits = soft_max(res['logits']).to('cpu').numpy()\n                b_labels = b_labels.to('cpu').numpy()\n                if list_of_logits is None:\n                    list_of_logits = logits\n                    list_of_labels = b_labels\n                else:\n                    list_of_logits = np.append(list_of_logits, logits, axis=0)\n                    list_of_labels = np.append(list_of_labels, b_labels, axis=0)\n                    \n                del batch, res\n                gc.collect()\n            \n            \n            \n        avg_train_loss = total_train_loss / len(train_dataset)\n        avg_val_loss = total_eval_loss / len(valid_dataset)\n        log_loss_val = log_loss(list_of_labels, list_of_logits)\n        memory = psutil.virtual_memory().percent\n\n         \n        f_time = time.time() - start_time\n        print(f'epoch: {epoch_i}, path: {fold+1}/{k_fold}, used_memory:{memory}%, time:{f_time:.2f}s, log_loss:{log_loss_val:.5f} '+\n              f'loss_train:{avg_train_loss:.5f}, loss_valid:{avg_val_loss:.5f}')\n\n        gc.collect()\n            \n        model.save_pretrained(f\"model_Deberta_base128k{fold}.h5\")\n        del model\n        gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-08-16T14:34:10.843482Z","iopub.execute_input":"2022-08-16T14:34:10.843944Z","iopub.status.idle":"2022-08-16T16:27:45.246515Z","shell.execute_reply.started":"2022-08-16T14:34:10.843904Z","shell.execute_reply":"2022-08-16T16:27:45.245444Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"tokenizer.save_pretrained(\"token_model_Deberta_base128.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-08-16T16:27:45.247895Z","iopub.execute_input":"2022-08-16T16:27:45.248979Z","iopub.status.idle":"2022-08-16T16:27:45.496348Z","shell.execute_reply.started":"2022-08-16T16:27:45.248936Z","shell.execute_reply":"2022-08-16T16:27:45.495419Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/feedback-prize-effectiveness/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-08-16T16:27:45.498390Z","iopub.execute_input":"2022-08-16T16:27:45.499057Z","iopub.status.idle":"2022-08-16T16:27:45.515532Z","shell.execute_reply.started":"2022-08-16T16:27:45.499019Z","shell.execute_reply":"2022-08-16T16:27:45.514543Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"df[\"essay_text\"] = df[\"essay_id\"].apply(lambda x: open(f'../input/feedback-prize-effectiveness/test/{x}.txt').read())\n\ndf['discourse_type'] = df['discourse_type'].apply(normalise)\ndf['discourse_text'] = df['discourse_text'].apply(normalise)\ndf['essay_text'] = df['essay_text'].apply(normalise)\n\ndf['text_features'] =  df['discourse_type'] + tokenizer.sep_token + df['discourse_text'] + tokenizer.sep_token + df['essay_text']\ndf.drop(['discourse_id', 'essay_id', 'essay_text', 'discourse_text', 'discourse_type'], axis=1, inplace=True )","metadata":{"execution":{"iopub.status.busy":"2022-08-16T16:27:45.516841Z","iopub.execute_input":"2022-08-16T16:27:45.517274Z","iopub.status.idle":"2022-08-16T16:27:45.537620Z","shell.execute_reply.started":"2022-08-16T16:27:45.517238Z","shell.execute_reply":"2022-08-16T16:27:45.536648Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"sentences = df.text_features.values\ndel df","metadata":{"execution":{"iopub.status.busy":"2022-08-16T16:27:45.539029Z","iopub.execute_input":"2022-08-16T16:27:45.539578Z","iopub.status.idle":"2022-08-16T16:27:45.544807Z","shell.execute_reply.started":"2022-08-16T16:27:45.539539Z","shell.execute_reply":"2022-08-16T16:27:45.543532Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"\n\ninput_ids = []\nattention_masks = []\nfor sent in tqdm(sentences):\n    encoded_dict = tokenizer.encode_plus(\n        sent, \n        add_special_tokens = True,\n        max_length = max_length,\n        pad_to_max_length = True,\n        return_attention_mask = True,\n        return_tensors = 'pt'\n    )\n    \n    input_ids.append(encoded_dict['input_ids'])\n    attention_masks.append(encoded_dict['attention_mask'])\n\ninput_ids = torch.cat(input_ids, dim=0)\nattention_masks = torch.cat(attention_masks, dim=0)","metadata":{"execution":{"iopub.status.busy":"2022-08-16T16:27:45.546591Z","iopub.execute_input":"2022-08-16T16:27:45.547084Z","iopub.status.idle":"2022-08-16T16:27:45.627871Z","shell.execute_reply.started":"2022-08-16T16:27:45.547049Z","shell.execute_reply":"2022-08-16T16:27:45.626632Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"dataset = TensorDataset(input_ids, attention_masks)","metadata":{"execution":{"iopub.status.busy":"2022-08-16T16:27:45.629549Z","iopub.execute_input":"2022-08-16T16:27:45.630519Z","iopub.status.idle":"2022-08-16T16:27:45.636597Z","shell.execute_reply.started":"2022-08-16T16:27:45.630478Z","shell.execute_reply":"2022-08-16T16:27:45.634910Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\n\nprediction_dataloader = DataLoader(\n    dataset,\n    sampler = SequentialSampler(dataset),\n    batch_size = batch_size\n)","metadata":{"execution":{"iopub.status.busy":"2022-08-16T16:27:45.638571Z","iopub.execute_input":"2022-08-16T16:27:45.639057Z","iopub.status.idle":"2022-08-16T16:27:45.648582Z","shell.execute_reply.started":"2022-08-16T16:27:45.639012Z","shell.execute_reply":"2022-08-16T16:27:45.647228Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"model.eval()\npredictions = None\nm = nn.Softmax(dim=1)\nfor batch in prediction_dataloader:\n    b_inputs_ids, b_input_mask = batch\n    b_inputs_ids = b_inputs_ids.to(device)\n    b_input_mask = b_input_mask.to(device)\n    with torch.no_grad():\n        outputs = model(b_inputs_ids, token_type_ids=None,\n                       attention_mask=b_input_mask)\n        \n        outputs = m(outputs.logits)\n    if predictions == None:\n        predictions = outputs\n    else:\n\n        predictions = torch.cat((predictions, outputs))\npredictions = predictions.to('cpu')","metadata":{"execution":{"iopub.status.busy":"2022-08-16T16:27:45.650474Z","iopub.execute_input":"2022-08-16T16:27:45.652643Z","iopub.status.idle":"2022-08-16T16:27:46.015684Z","shell.execute_reply.started":"2022-08-16T16:27:45.652612Z","shell.execute_reply":"2022-08-16T16:27:46.014336Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"predictions","metadata":{"execution":{"iopub.status.busy":"2022-08-16T16:27:46.016792Z","iopub.status.idle":"2022-08-16T16:27:46.017887Z","shell.execute_reply.started":"2022-08-16T16:27:46.017608Z","shell.execute_reply":"2022-08-16T16:27:46.017634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit = pd.read_csv('/kaggle/input/feedback-prize-effectiveness/sample_submission.csv')\nsubmission = pd.DataFrame({'discourse_id':submit['discourse_id'],'Adequate':predictions[:,1],'Effective':predictions[:,2],'Ineffective':predictions[:,0]})\nsubmission.to_csv(\"/kaggle/working/submission.csv\",index = False)","metadata":{"execution":{"iopub.status.busy":"2022-08-16T16:27:46.019140Z","iopub.status.idle":"2022-08-16T16:27:46.020160Z","shell.execute_reply.started":"2022-08-16T16:27:46.019894Z","shell.execute_reply":"2022-08-16T16:27:46.019918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}